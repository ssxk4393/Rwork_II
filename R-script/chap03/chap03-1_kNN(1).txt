##################################################
#  k-Nearest Neighbors(kNN) 알고리즘 분류모형    #
##################################################
# 최근접 이웃(kNN) : k개의 인접한 값을 찾아서 분류 
# 비모수적 방법의 분류모형 
# 거리를 기반으로 계산하여 분류모형 생성 
# 유클리드안 거리 계산법 적용 


# kNN 개념 예제 : 과일(2개), 단백질(2개), 채소(2개) 
# 품목   : (단맛, 아삭거림)  분류 
# grape  : (8, 5)            과일(1)
# fish   : (2, 3)          단백질(2) 
# carrot : (7, 10)           채소(3)
# orange : (7, 3)            과일(1) 
# celery : (3, 8)            채소(3)
# cheese : (1, 1)          단백질(2) 


# 1. train data 생성
# y변수 factor vector : 분류그룹(1-과일, 2-단백질, 3-채소)
train_df = data.frame(x1 = c(8, 2, 7, 7, 3, 1), 
                      x2 = c(5, 3, 10, 3, 8, 1), 
                      y=factor(c(1, 2, 3, 1, 3, 2)))
train_df
plot(train_df$x1, train_df$x2, col=train_df$y, xlab='단맛', ylab='아삭거림')


# 2. test data 생성 : 새로운 항목 - 토마토(6,4), 땅콩(3,8), 사과(10,9)
test_df = data.frame(x1=c(6,3,10), x2=c(4,8,9))
test_df

# 3. kNN 분류모델 생성 
install.packages('class')
library(class) # knn()함수 제공 

# 형식) knn(훈련데이터(y제외), 검정데이터, 훈련데이터 y변수, k)
knn(train_df[, -3], test_df, train_df$y, k=3) # prob=TRUE : 예측 의미


###############################
# kNN 분류모형 : 간단 실습    # 
###############################
# 1. data 생성 
data(iris)
set.seed(415) # random 결과를 동일하게 지정
idx = sample(1:nrow(iris), 0.7*nrow(iris) )
training = iris[idx, ]
testing = iris[-idx, ]
training
testing
names(training)

# 2. 분류모델 생성 
model.knn = knn(training[, -5], testing[, -5], training$Species, k = 3, prob=TRUE)
model.knn
summary(model.knn)


# 3. 분류모델 평가(검정데이터 적용) 
table(model.knn, testing$Species)


# 4. 분류모델 성능 평가 - 분류 정확도 
# 분류정확도 = 정분류 / test set 길이 


